Este documento describe para quÃ© sirve cada carpeta y archivo generado por el script de inicializaciÃ³n y las ampliaciones posteriores del proyecto (Flask + RAG + comparador de LLMs).

Nota: La lÃ³gica se ha ido implementando fase a fase.
Actualmente:

Ingesta de documentos: estable y validada.

Ingesta web: en pruebas (ya lanza runs y guarda stdout/artefactos).

Vector store: pendiente de integrar.

ğŸ“‚ RaÃ­z del proyecto

README.md â€” Resumen del proyecto y cÃ³mo empezar.

.gitignore â€” Evita versionar artefactos (venv, datos, modelos, configuraciones sensibles).

.env.example â€” Plantilla de variables sensibles (claves, tokens). Copiar a .env (no versionar).

requirements.txt / requirements-dev.txt â€” Dependencias de runtime / desarrollo.

wsgi.py â€” Punto de entrada para despliegues WSGI (gunicorn/uwsgi).

âš™ï¸ ConfiguraciÃ³n

config/ â€” ConfiguraciÃ³n externa (no incluye secretos).

settings.example.toml â€” Plantilla de configuraciÃ³n (copiar a settings.toml).

logging.yaml â€” ConfiguraciÃ³n de logging estructurado.

ğŸ“‘ DocumentaciÃ³n

docs/ â€” DocumentaciÃ³n del proyecto:

arquitectura.md, decisiones.md, evaluacion.md, despliegue.md.

ğŸ“Š Datos

data/

raw/ â€” Fuentes originales intactas (PDFs, DOCX, HTML, JSON).

processed/ â€” Texto normalizado, chunks, datasets y logs de ingesta.

runs/ â€” Directorios por ejecuciÃ³n de ingestas.

docs/run_<id>/stdout.txt, summary.json.

web/run_<id>/stdout.txt, fetch_index.json, raw/*.html.

tracking.sqlite â€” Base de datos SQLite de seguimiento (Source, IngestionRun, Document, Chunk).

logs/

ingestion.log â€” Log global de ingestas (documentos y webs).

web/ â€” Snapshots HTML/JSON de crawling web.

ğŸ“¦ Modelos y vector store

models/ â€” Artefactos del vector store y cachÃ©s.

embeddings/ â€” CachÃ© de embeddings.

faiss/ â€” Ãndices FAISS.

chroma/ â€” Colecciones ChromaDB.

ğŸ› ï¸ Scripts

scripts/

ingest_documents.py â€” Pipeline de ingesta de documentos (chunking, fingerprints, logging).

ingest_web.py â€” Pipeline de ingesta web (sitemap, BFS requests, Selenium).

check_sources.py â€” Utilidad para listar fuentes y runs en BD.

ğŸ“‚ App Flask

app/init.py â€” create_app(): carga config, logging y DB.

app/extensions/

db.py â€” SQLAlchemy + sesiones.

logging.py â€” Logging estructurado.

app/blueprints/

admin/

routes_data_sources.py â€” Lista de fuentes (docs/web).

routes_ingesta_docs.py â€” CRUD y ejecuciÃ³n de ingestas de documentos.

routes_ingesta_web.py â€” ConfiguraciÃ³n/ejecuciÃ³n de ingestas web (en progreso).

chat/ â€” Chat RAG y comparador (pendiente).

dashboard/ â€” KPIs de ingesta/retrieval/evaluaciÃ³n (pendiente).

app/models/

Source â€” Origen de datos (type=docs|web, url, config).

IngestionRun â€” EjecuciÃ³n de ingesta (status, meta, stdout, cmd, duraciÃ³n).

Document â€” Documento ingerido (path, hash, size, mtime, metadata).

Chunk â€” Fragmentos de texto.

app/templates/admin/

ingesta_docs.html â€” UI de ingesta de documentos.

ingesta_web.html â€” UI de ingesta web (CRUD fuentes, runs, mÃ©tricas).

app/static/css/custom.css â€” Estilos unificados.

ğŸ§ª Tests

tests/

test_ingestion.py â€” Verifica ingesta de documentos.

test_rag_pipeline.py â€” Flujo E2E RAG (pendiente).

test_retrievers.py, test_generators.py, etc.

âœ… Flujos actuales

Ingesta de documentos

OK: crea fuentes, ejecuta ingestas, genera chunks y mÃ©tricas.

Ingesta web

En progreso: ya se ejecutan runs (sitemap, requests, selenium).

Artefactos (stdout.txt, fetch_index.json) se guardan en runs/web/run_<id>.

AÃºn falta integrar chunking de HTML â†’ Chunk en BD.

Vector store

Pendiente: conectar Chunk a FAISS/Chroma.

âš¡ Super-prompt â€” Siguiente Paso

Rol: Tech lead e IC senior en un proyecto Flask+SQLAlchemy (TFM RAG).
Objetivo: Terminar de robustecer la ingesta web y comenzar la integraciÃ³n con el vector store.
Estado:

Ingesta de documentos: estable.

Ingesta web: runs ya ejecutan, pero falta persistir pÃ¡ginas y generar Chunks como en docs.

Vector store: aÃºn sin poblar.

ğŸ¯ Prompt de continuaciÃ³n
    Rol: ActÃºa como tech lead para el proyecto Flask+SQLAlchemy de ingesta RAG.

    Objetivo inmediato:
    1. Revisar `scripts/ingest_web.py` y `routes_ingesta_web.py` para que:
    - Cada pÃ¡gina descargada genere un `Document` y sus `Chunk`s en BD (igual que ingest_documents.py).
    - Se guarden en `data/processed/runs/web/run_<id>/summary.json` mÃ©tricas claras (pÃ¡ginas, chunks, bytes).
    - La UI muestre las mÃ©tricas en la tabla de ejecuciones.

    2. Validar que los `stdout.txt` y `summary.json` se actualizan bien en la UI (Ver salida / Artefactos).

    3. Preparar el pipeline para que los `Chunk`s de web sean despuÃ©s indexables en FAISS/Chroma (vector store).

    Restricciones:
    - Sin frameworks nuevos, solo Flask + SQLAlchemy + libs ya usadas (requests, selenium, bs4).
    - CÃ³digo claro y trazable.

    Plan:
    - Pedir solo los ficheros a modificar (seguro: `scripts/ingest_web.py`, quizÃ¡ `routes_ingesta_web.py`, y modelos si hace falta un `Page`).
    - Entregar archivos completos listos para pegar.
    - Incluir comandos de prueba (PowerShell) y cÃ³mo validar en la UI.

    Contexto actual:
    - BD tracking.sqlite con Source, IngestionRun, Document, Chunk.
    - Ingesta de docs ya validada (crea Source, Document, Chunk).
    - Ingesta web crea Source y Run, pero no aÃºn Document/Chunk.